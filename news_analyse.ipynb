{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import der benötigten Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import nltk\n",
    "import csv\n",
    "import operator\n",
    "import pandas    as pd\n",
    "from pymongo     import MongoClient\n",
    "from nltk        import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Stopwords\n",
    "Die 1. Zelle muss nur beim ersten Mal ausgeführt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('german'))\n",
    "stop.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konvertierung der .txt-Datenquellen in .csv-Dateien\n",
    "Muss nur beim ersten Mal ausgeführt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_csv = pd.read_csv ('deu_news_2015_3M-sentences.txt', header = None, delimiter='\\t')\n",
    "sentences_csv.to_csv ('sentences_de.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entfernen der Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentences):\n",
    "    queue = []\n",
    "    for sentence in sentences:\n",
    "        result = ' '.join([i for i in sentence.lower().split() if i not in stop]) #Habe hier eine Liste statt einer Menge genommen, da sonst die Reihenfolge geändert wird\n",
    "        queue.append(result)\n",
    "    return queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nostop = remove_stopwords(sentences_csv[1]) #(sentences_csv[1][100:200]) Für Test nur 100 Datensätze verwenden\n",
    "df = pd.DataFrame(nostop)\n",
    "df.to_csv('sentences_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbindung mit mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string      = \"mongodb://localhost:27017\"\n",
    "db                     = MongoClient(connection_string)\n",
    "sentences              = db.dw.sentences\n",
    "sentences_preprocessed = db.dw.sentences_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences und Stopwords der Database in mongoDB hinzufügen\n",
    "\n",
    "`read_csv()` liest eine .csv-Datei ein und gibt ein Dictionary zurück, dass dann mit `save_to_mongo()` in einer Collection gespeichert wird. Dafür kann zunächst die Collection gelöscht werden (`drop_collection = True`). Sonst werden die Daten zusätzlich in die Collection eingefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, columns):\n",
    "    reader = open(path, 'r', encoding='utf-8')\n",
    "    return csv.DictReader(reader, columns)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_mongo(collection, path, columns, drop_collection):\n",
    "    if drop_collection:\n",
    "        collection.drop()\n",
    "    data = read_csv(path, columns)\n",
    "    result = collection.insert_many(data)\n",
    "    print('%d rows are saved to \"%s\" collection successfully!' % (len(result.inserted_ids), collection.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_mongo(sentences, 'sentences_de.csv', ('id','sentence'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_mongo(sentences_preprocessed, 'sentences_preprocessed.csv', ('s'), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn ich die als Column-Name gleich `sentence` genommen habe, dann hat er daraus eine Spalte `s`, eine `e`, eine `n` und so weiter gemacht...Deswegen hier mit der späteren Umbenennung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_preprocessed.update_many( {}, { '$rename': { \"s\": \"sentence\" } } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = nostop[:2000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bigrams(data):\n",
    "    bigram_dict = dict()\n",
    "    for text in data:\n",
    "        bigrams = list(nltk.bigrams(text.split()))\n",
    "        for bigram in bigrams:\n",
    "            if bigram in bigram_dict:\n",
    "                bigram_dict[bigram] += 1\n",
    "            else:\n",
    "                bigram_dict[bigram] = 1\n",
    "    return bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_most_frequent(dictionary, k):\n",
    "    sorted_dictionary =  dict(sorted(dictionary.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    result = sorted_dictionary.items()\n",
    "    return list(result)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_most_frequent(data):\n",
    "    for i in range(len(data)):\n",
    "        words, frequency = data[i]\n",
    "        print('Platz ', i+1, ': Die Wortkombination \"', ' '.join(words), \\\n",
    "              '\" kommt in den Daten ', frequency, ' mal vor.', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_most_frequent_bigrams(data, k):\n",
    "    bigram_dict   = count_bigrams(data)\n",
    "    most_frequent = get_k_most_frequent(bigram_dict, k)\n",
    "    pretty_print_most_frequent(most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_k_most_frequent_bigrams(test_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDos: \n",
    "- Einfügen von sentences_preprocessed in DB ohne Umweg über DataFrame und .csv\n",
    "- Spaltenname ohne Umbenennung\n",
    "- Daten für Analyse aus DB ziehen\n",
    "- Das Ergebnis (komplettes Bigram-Dict?) in der DB speichern\n",
    "- Weitere Analysen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
