{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import der benötigten Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import nltk\n",
    "import csv\n",
    "import pandas    as pd\n",
    "from pymongo     import MongoClient\n",
    "from nltk        import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Stopwords\n",
    "Die 1. Zelle muss nur beim ersten Mal ausgeführt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('german'))\n",
    "stop.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konvertierung der .txt-Datenquellen in .csv-Dateien\n",
    "Muss nur beim ersten Mal ausgeführt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_csv = pd.read_csv ('deu_news_2015_3M-sentences.txt', header = None, delimiter='\\t')\n",
    "sentences_csv.to_csv ('sentences_de.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entfernen der Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentences):\n",
    "    queue = []\n",
    "    for sentence in sentences:\n",
    "        result = ' '.join([i for i in sentence.lower().split() if i not in stop]) #Habe hier eine Liste statt einer Menge genommen, da sonst die Reihenfolge geändert wird\n",
    "        queue.append(result)\n",
    "    return queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nostop = remove_stopwords(sentences_csv[1]) #(sentences_csv[1][100:200]) Für Test nur 100 Datensätze verwenden\n",
    "df = pd.DataFrame(nostop)\n",
    "df.to_csv('sentences_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbindung mit mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string      = \"mongodb://localhost:27017\"\n",
    "db                     = MongoClient(connection_string)\n",
    "sentences              = db.dw.sentences\n",
    "sentences_preprocessed = db.dw.sentences_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences und Stopwords der Database in mongoDB hinzufügen\n",
    "\n",
    "`read_csv()` liest eine .csv-Datei ein und gibt ein Dictionary zurück, dass dann mit `save_to_mongo()` in einer Collection gespeichert wird. Dafür kann zunächst die Collection gelöscht werden (`drop_collection = True`). Sonst werden die Daten zusätzlich in die Collection eingefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, columns):\n",
    "    reader = open(path, 'r', encoding='utf-8')\n",
    "    return csv.DictReader(reader, columns)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_mongo(collection, path, columns, drop_collection):\n",
    "    if drop_collection:\n",
    "        collection.drop()\n",
    "    data = read_csv(path, columns)\n",
    "    result = collection.insert_many(data)\n",
    "    print('%d rows are saved to \"%s\" collection successfully!' % (len(result.inserted_ids), collection.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2646184 rows are saved to \"sentences\" collection successfully!\n"
     ]
    }
   ],
   "source": [
    "save_to_mongo(sentences, 'sentences_de.csv', ('id','sentence'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 rows are saved to \"sentences_preprocessed\" collection successfully!\n"
     ]
    }
   ],
   "source": [
    "save_to_mongo(sentences_preprocessed, 'sentences_preprocessed.csv', ('s'), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn ich die als Column-Name gleich `sentence` genommen habe, dann hat er daraus eine Spalte `s`, eine `e`, eine `n` und so weiter gemacht...Deswegen hier mit der späteren Umbenennung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x1b500124a40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_preprocessed.update_many( {}, { '$rename': { \"s\": \"sentence\" } } )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
